{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbuvQeHIaecX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from functools import wraps\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import matplotlib as plt\n",
    "import folium\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except BaseException:\n",
    "    import pickle\n",
    "\n",
    "# Modeling\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, STATUS_FAIL, Trials\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, max_error, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "\n",
    "#https://towardsdatascience.com/an-example-of-hyperparameter-optimization-on-xgboost-lightgbm-and-catboost-using-hyperopt-12bc41a271e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbuvQeHIaecX"
   },
   "outputs": [],
   "source": [
    "def timer(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time()\n",
    "        print('Elapsed time: {}'.format(end-start))\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "# rmse\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "@timer\n",
    "def get_date(base_dir):\n",
    "    new_time = []\n",
    "    for file in listdir(base_dir):\n",
    "        file_path = f'{base_dir}/{file}'\n",
    "        match=file.split(\"_\")[1]\n",
    "        date = pd.to_datetime(match, format = \"%Y%m%d%H\").strftime('%d/%m/%Y')\n",
    "        time = (datetime.strptime(match, \"%Y%m%d%H\") + timedelta(hours=6)).strftime('%H:%M')\n",
    "        new_time.append(date + \" \" + time)\n",
    "    return new_time\n",
    "\n",
    "\n",
    "@timer\n",
    "def get_variables(base_dir, var_list, diccionario, nz=26):\n",
    "    d3_var = [\"HGTprs\", \"CLWMRprs\", \"RHprs\",\"Velprs\",\"UGRDprs\",\"VGRDprs\",\"TMPprs\"]\n",
    "    d2_var = [\"HGTsfc\", \"MSLETmsl\", \"PWATclm\", \"RH2m\", \"Vel100m\", \"UGRD100m\", \"VGRD100m\",\n",
    "            \"Vel80m\", \"UGRD80m\", \"VGRD80m\", \"Vel10m\", \"UGRD10m\", \"VGRD10m\", \"GUSTsfc\",\n",
    "            \"TMPsfc\", \"TMP2m\", \"no4LFTXsfc\", \"CAPEsfc\", \"SPFH2m\", \"SPFH80m\"]\n",
    "\n",
    "    lst = []\n",
    "  \n",
    "    for file in listdir(base_dir):\n",
    "        file_path = f'{base_dir}/{file}'\n",
    "        e_file = []\n",
    "        for key, value in diccionario.items():\n",
    "\n",
    "            if key in set(var_list).intersection(d3_var): #d3_var:\n",
    "                corte = value[0] + int(((value[1])/26)*nz)\n",
    "                e_file.append(np.fromfile(file_path, dtype=np.float32)[value[0]:corte])\n",
    "\n",
    "            elif key in set(var_list).intersection(d2_var):#d2_var:\n",
    "                e_file.append(np.fromfile(file_path, dtype=np.float32)[value[0]:value[1]])\n",
    "        lst.append(e_file)\n",
    "  \n",
    "  return lst\n",
    "\n",
    "@timer\n",
    "def setup_x(dataframe):\n",
    "  \"\"\"Flat variables values for model training\"\"\"\n",
    "    dataframe.reset_index(level=0, inplace=True)\n",
    "    row_list =[] \n",
    "    for index, rows in dataframe.iterrows(): \n",
    "        my_list = [rows.RHprs, rows.Velprs, rows.TMPprs, rows.Vel100m, rows.Vel80m,rows.TMPsfc, rows.SPFH80m]\n",
    "        row_list.append(my_list) \n",
    "\n",
    "    a = [np.concatenate(row_list[i]) for i in range(len(row_list))]\n",
    "    train_ = pd.DataFrame(a, index=dataframe[\"index\"])\n",
    "    return train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aGakaqyhTMiK"
   },
   "outputs": [],
   "source": [
    "# Bayesian optimization\n",
    "@timer\n",
    "class HPOpt(object):\n",
    "\n",
    "    def __init__(self, x_train, x_test, y_train, y_test):\n",
    "        self.x_train = x_train\n",
    "        self.x_test  = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test  = y_test\n",
    "\n",
    "    def process(self, fn_name, space, trials, algo, max_evals):\n",
    "        fn = getattr(self, fn_name)\n",
    "        try:\n",
    "            result = fmin(fn=fn, space=space, algo=algo, max_evals=max_evals, trials=trials)\n",
    "        except Exception as e:\n",
    "            return {'status': STATUS_FAIL,\n",
    "                    'exception': str(e)}\n",
    "        return result, trials\n",
    "\n",
    "    def xgb_reg(self, para):\n",
    "        reg = xgb.XGBRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def lgb_reg(self, para):\n",
    "        reg = lgb.LGBMRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def ctb_reg(self, para):\n",
    "        reg = ctb.CatBoostRegressor(**para['reg_params'])\n",
    "        return self.train_reg(reg, para)\n",
    "\n",
    "    def train_reg(self, reg, para):\n",
    "        reg.fit(self.x_train, self.y_train,\n",
    "                eval_set=[(self.x_train, self.y_train), (self.x_test, self.y_test)],\n",
    "                **para['fit_params'])\n",
    "        pred = reg.predict(self.x_test)\n",
    "        loss = para['loss_func'](self.y_test, pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f3pCUcQrafVk",
    "outputId": "2ffe71ba-1a81-4361-d069-c75a2d9c434e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the data...\n"
     ]
    }
   ],
   "source": [
    "# Data loading \n",
    "\n",
    "base_dir = '/content/drive/My Drive/datos/GFS_data'\n",
    "power_csv = '/content/pow_data.csv'\n",
    "power_csv=\"/content/power_data.csv\"\n",
    "gfs_dict_path = '/content/power_data.csv'\n",
    "\n",
    "gfs_data_dict = {\n",
    " 'CAPEsfc': [23283, 23400], 'CLWMRprs': [3042, 6084], 'GUSTsfc': [22815, 22932],\n",
    " 'HGTprs': [0, 3042], 'HGTsfc': [21294, 21411], 'MSLETmsl': [21411, 21528], 'PWATclm': [21528, 21645],\n",
    " 'RH2m': [21645, 21762], 'RHprs': [6084, 9126], 'SPFH2m': [23400, 23517], 'SPFH80m': [23517, 23634],\n",
    " 'TMP2m': [23049, 23166], 'TMPprs': [18252, 21294], 'TMPsfc': [22932, 23049], 'UGRD100m': [21879, 21996],\n",
    " 'UGRD10m': [22581, 22698], 'UGRD80m': [22230, 22347], 'UGRDprs': [12168, 15210], 'VGRD100m': [21996, 22113],\n",
    " 'VGRD10m': [22698, 22815], 'VGRD80m': [22347, 22464], 'VGRDprs': [15210, 18252], 'Vel100m': [21762, 21879],\n",
    " 'Vel10m': [22464, 22581], 'Vel80m': [22113, 22230], 'Velprs': [9126, 12168], 'no4LFTXsfc': [23166, 23283]\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "eDuWIg5HbNIi",
    "outputId": "a26f8bb8-453f-49cf-817c-200d74377858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 20.98387360572815\n",
      "Elapsed time: 2606.9707458019257\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Selection of variables and pre-processing\n",
    "list_var = [\"RHprs\", \"Velprs\", \"TMPprs\", \"Vel100m\",\"Vel80m\", \"TMPsfc\", \"SPFH80m\"]\n",
    "\n",
    "lista_dates = get_date(base_dir)\n",
    "\n",
    "variables_ready = get_variables(base_dir, list_var, gfs_data_dict, nz=5)\n",
    "\n",
    "\n",
    "df_power = pd.read_csv(power_csv)\n",
    "#when windows\n",
    "#df_power = pd.read_csv(power_csv, encoding='utf8', sep='\\t')\n",
    "\n",
    "\n",
    "df_gfs = pd.DataFrame(data=variables_ready, index=lista_dates, columns=list_var)\n",
    "df_power['date'] =  pd.to_datetime(df_power['date'], format='%d/%m/%Y %H:%M')\n",
    "df_power = df_power.set_index(\"date\")\n",
    "\n",
    "df_gfs.sort_index(axis=0, level=None, ascending=True, inplace=True)\n",
    "df_gfs = df_gfs.loc[:'31/12/2016 00:00']\n",
    "df_power.sort_index(axis=0, level=None, ascending=True, inplace=True)\n",
    "df_power = df_power.loc[:'31/12/2016 00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Rai_n-J8bkqB",
    "outputId": "aa54198f-2bf7-49ad-c673-270fa28492da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 9.598525285720825\n"
     ]
    }
   ],
   "source": [
    "# df intersection based on dates\n",
    "trained = df_power.merge(df_gfs, left_index=True, right_index=True) \n",
    "\n",
    "# Data preparation for model train\n",
    "trained = df_power.merge(df_gfs, left_index=True, right_index=True) # df intersection based on dates\n",
    "\n",
    "df_X = trained[[x for x in trained.columns if x != 'Production']]\n",
    "\n",
    "X = setup_x(df_X)\n",
    "y = pd.DataFrame(trained[\"Production\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "M6jwPJTebtVa",
    "outputId": "c44c9950-8968-418d-c0d7-b8defd53af69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting LGBMRegressor model...\n",
      "Finished fitting LGBMRegressor model\n"
     ]
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "#LGBMRegressor\n",
    "gbm0 = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    num_leaves=60,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=1000)\n",
    "\n",
    "print(\"Fitting LGBMRegressor model...\")\n",
    "gbm_fit = gbm0.fit(X_train, y_train, eval_metric='rmse')\n",
    "print(\"Finished fitting LGBMRegressor model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "Jsf3ROz4b8ks",
    "outputId": "6a2ca58e-cc3c-46a6-bc4b-058ab767abed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance_score 0.29043962199610385\n",
      "max_error 169229.4844695173\n",
      "mean_absolute_error 42396.972129664144\n",
      "mean_squared_error 2888827639.8226266\n",
      "mean_squared_log_error 70.51175845464078\n",
      "median_absolute_error 34414.01404656979\n",
      "r2_score 0.2896459877538511\n",
      "rmse 53747.8152097611\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "predict_lightGBM = gbm0.predict(X_test)\n",
    "\n",
    "y_trained = np.array(trained['Production'])\n",
    "y_pred = predict_lightGBM\n",
    "y_truth = np.array(y_test)\n",
    "print('explained_variance_score', explained_variance_score(y_truth, y_pred))\n",
    "print('max_error', max_error(y_truth, y_pred))\n",
    "print('mean_absolute_error', mean_absolute_error(y_truth, y_pred))\n",
    "print('mean_squared_error', mean_squared_error(y_truth, y_pred))\n",
    "print('mean_squared_log_error', mean_squared_log_error(y_truth**2, y_pred**2))\n",
    "print('median_absolute_error', median_absolute_error(y_truth, y_pred))\n",
    "print('r2_score', r2_score(y_truth, y_pred))\n",
    "print('rmse', rmse(y_truth, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "colab_type": "code",
    "id": "gKcCuBwycuO4",
    "outputId": "e3541962-cacd-4cc6-a3ec-9557cca61c63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed: 22.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM best score -42349.12652737538\n",
      "GBM best params {'max_depth': 6, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "optimization_dict = {'max_depth': [2,4,6],\n",
    "                     'n_estimators': [50,100,200]}\n",
    "\n",
    "model_gbm = GridSearchCV(gbm0, optimization_dict, \n",
    "                     scoring='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "model_gbm.fit(X_train, y_train)\n",
    "print(\"GBM best score\", model_gbm.best_score_)\n",
    "print(\"GBM best params\", model_gbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "KeUMW0uGdOBI",
    "outputId": "5da5391c-d62d-41c3-a51d-3cc6ede89484"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is [21]\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's l2: 6.59782e+09\n",
      "[2]\ttraining's l2: 6.59782e+09\n",
      "[3]\ttraining's l2: 6.59782e+09\n",
      "[4]\ttraining's l2: 6.59782e+09\n",
      "[5]\ttraining's l2: 6.59782e+09\n",
      "[6]\ttraining's l2: 6.59782e+09\n",
      "[7]\ttraining's l2: 6.59782e+09\n",
      "[8]\ttraining's l2: 6.59782e+09\n",
      "[9]\ttraining's l2: 6.59782e+09\n",
      "[10]\ttraining's l2: 6.59782e+09\n",
      "[11]\ttraining's l2: 6.59782e+09\n",
      "[12]\ttraining's l2: 6.59782e+09\n",
      "[13]\ttraining's l2: 6.59782e+09\n",
      "[14]\ttraining's l2: 6.59782e+09\n",
      "[15]\ttraining's l2: 6.59782e+09\n",
      "[16]\ttraining's l2: 6.59782e+09\n",
      "[17]\ttraining's l2: 6.59782e+09\n",
      "[18]\ttraining's l2: 6.59782e+09\n",
      "[19]\ttraining's l2: 6.59782e+09\n",
      "[20]\ttraining's l2: 6.59782e+09\n",
      "[21]\ttraining's l2: 6.59782e+09\n",
      "[22]\ttraining's l2: 6.59782e+09\n",
      "[23]\ttraining's l2: 6.59782e+09\n",
      "[24]\ttraining's l2: 6.59782e+09\n",
      "[25]\ttraining's l2: 6.59782e+09\n",
      "[26]\ttraining's l2: 6.59782e+09\n",
      "[27]\ttraining's l2: 6.59782e+09\n",
      "[28]\ttraining's l2: 6.59782e+09\n",
      "[29]\ttraining's l2: 6.59782e+09\n",
      "[30]\ttraining's l2: 6.59782e+09\n",
      "[31]\ttraining's l2: 6.59782e+09\n",
      "[32]\ttraining's l2: 6.59782e+09\n",
      "[33]\ttraining's l2: 6.59782e+09\n",
      "[34]\ttraining's l2: 6.59782e+09\n",
      "[35]\ttraining's l2: 6.59781e+09\n",
      "[36]\ttraining's l2: 6.59781e+09\n",
      "[37]\ttraining's l2: 6.59781e+09\n",
      "[38]\ttraining's l2: 6.59781e+09\n",
      "[39]\ttraining's l2: 6.59781e+09\n",
      "[40]\ttraining's l2: 6.59781e+09\n",
      "[41]\ttraining's l2: 6.59781e+09\n",
      "[42]\ttraining's l2: 6.59781e+09\n",
      "[43]\ttraining's l2: 6.59781e+09\n",
      "[44]\ttraining's l2: 6.59781e+09\n",
      "[45]\ttraining's l2: 6.59781e+09\n",
      "[46]\ttraining's l2: 6.59781e+09\n",
      "[47]\ttraining's l2: 6.59781e+09\n",
      "[48]\ttraining's l2: 6.59781e+09\n",
      "[49]\ttraining's l2: 6.59781e+09\n",
      "[50]\ttraining's l2: 6.59781e+09\n",
      "[51]\ttraining's l2: 6.59781e+09\n",
      "[52]\ttraining's l2: 6.59781e+09\n",
      "[53]\ttraining's l2: 6.59781e+09\n",
      "[54]\ttraining's l2: 6.59781e+09\n",
      "[55]\ttraining's l2: 6.59781e+09\n",
      "[56]\ttraining's l2: 6.59781e+09\n",
      "[57]\ttraining's l2: 6.59781e+09\n",
      "[58]\ttraining's l2: 6.59781e+09\n",
      "[59]\ttraining's l2: 6.59781e+09\n",
      "[60]\ttraining's l2: 6.59781e+09\n",
      "[61]\ttraining's l2: 6.59781e+09\n",
      "[62]\ttraining's l2: 6.59781e+09\n",
      "[63]\ttraining's l2: 6.59781e+09\n",
      "[64]\ttraining's l2: 6.59781e+09\n",
      "[65]\ttraining's l2: 6.59781e+09\n",
      "[66]\ttraining's l2: 6.59781e+09\n",
      "[67]\ttraining's l2: 6.59781e+09\n",
      "[68]\ttraining's l2: 6.59781e+09\n",
      "[69]\ttraining's l2: 6.59781e+09\n",
      "[70]\ttraining's l2: 6.59781e+09\n",
      "[71]\ttraining's l2: 6.59781e+09\n",
      "[72]\ttraining's l2: 6.59781e+09\n",
      "[73]\ttraining's l2: 6.59781e+09\n",
      "[74]\ttraining's l2: 6.59781e+09\n",
      "[75]\ttraining's l2: 6.59781e+09\n",
      "[76]\ttraining's l2: 6.59781e+09\n",
      "[77]\ttraining's l2: 6.59781e+09\n",
      "[78]\ttraining's l2: 6.59781e+09\n",
      "[79]\ttraining's l2: 6.59781e+09\n",
      "[80]\ttraining's l2: 6.59781e+09\n",
      "[81]\ttraining's l2: 6.59781e+09\n",
      "[82]\ttraining's l2: 6.59781e+09\n",
      "[83]\ttraining's l2: 6.59781e+09\n",
      "[84]\ttraining's l2: 6.59781e+09\n",
      "[85]\ttraining's l2: 6.59781e+09\n",
      "[86]\ttraining's l2: 6.59781e+09\n",
      "[87]\ttraining's l2: 6.59781e+09\n",
      "[88]\ttraining's l2: 6.59781e+09\n",
      "[89]\ttraining's l2: 6.59781e+09\n",
      "[90]\ttraining's l2: 6.59781e+09\n",
      "[91]\ttraining's l2: 6.59781e+09\n",
      "[92]\ttraining's l2: 6.59781e+09\n",
      "[93]\ttraining's l2: 6.59781e+09\n",
      "[94]\ttraining's l2: 6.59781e+09\n",
      "[95]\ttraining's l2: 6.59781e+09\n",
      "[96]\ttraining's l2: 6.59781e+09\n",
      "[97]\ttraining's l2: 6.59781e+09\n",
      "[98]\ttraining's l2: 6.59781e+09\n",
      "[99]\ttraining's l2: 6.59781e+09\n",
      "[100]\ttraining's l2: 6.59781e+09\n",
      "Finished first 10 rounds...\n",
      "Saving model...\n",
      "Dumping model to JSON...\n",
      "Feature importances: [1, 0, 0, 1, 1, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 1, 1, 0, 0, 2, 87, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 2, 0, 2, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 4, 1, 0, 0, 0, 0, 2, 3, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 0, 1, 2, 3, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 2, 1, 0, 0, 0, 2, 1, 0, 0, 19, 1, 0, 0, 0, 0, 1, 2, 1, 1, 8, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 3, 0, 5, 4, 0, 0, 3, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 2, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 1, 2, 1, 1, 2, 0, 3, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 6, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 1, 2, 5, 3, 0, 1, 1, 0, 3, 0, 0, 2, 0, 0, 2, 0, 1, 1, 0, 1, 0, 0, 1, 2, 0, 0, 0, 1, 0, 0, 0, 1, 2, 4, 1, 3, 1, 3, 0, 0, 0, 0, 2, 0, 1, 2, 1, 1, 0, 0, 0, 0, 2, 2, 0, 4, 0, 2, 1, 3, 1, 2, 0, 0, 0, 0, 5, 0, 3, 1, 1, 0, 0, 0, 4, 0, 1, 0, 2, 2, 0, 1, 0, 2, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 2, 0, 0, 1, 0, 0, 2, 1, 3, 2, 1, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 0, 0, 0, 1, 0, 5, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 3, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 3, 0, 4, 0, 0, 4, 3, 1, 1, 0, 0, 0, 1, 0, 5, 0, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 3, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 3, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 2, 0, 0, 2, 0, 1, 1, 0, 0, 1, 1, 2, 0, 0, 1, 2, 3, 0, 3, 1, 1, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 6, 1, 0, 0, 1, 0, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 1, 3, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 3, 2, 0, 1, 0, 3, 2, 0, 1, 1, 1, 1, 2, 0, 1, 0, 2, 1, 1, 0, 0, 0, 0, 1, 0, 2, 3, 1, 0, 0, 0, 1, 4, 0, 2, 2, 0, 1, 1, 0, 1, 1, 1, 3, 0, 0, 0, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 8, 3, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 3, 3, 1, 0, 0, 0, 1, 1, 0, 3, 0, 0, 3, 1, 2, 1, 2, 1, 0, 1, 1, 0, 0, 1, 3, 2, 4, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 0, 1, 0, 0, 1, 0, 0, 3, 0, 1, 0, 1, 2, 2, 0, 2, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 5, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 2, 1, 1, 3, 1, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 0, 2, 0, 1, 1, 0, 4, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 4, 0, 3, 0, 0, 0, 0, 2, 1, 0, 3, 2, 1, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 1, 0, 1, 2, 0, 1, 3, 2, 0, 0, 0, 1, 0, 1, 0, 1, 1, 2, 1, 1, 2, 0, 1, 0, 1, 0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 3, 0, 3, 0, 0, 3, 1, 1, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 2, 2, 1, 1, 3, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 2, 1, 1, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 1, 4, 1, 0, 0, 1, 1, 0, 4, 1, 0, 0, 0, 2, 6, 0, 0, 1, 1, 0, 1, 2, 0, 0, 1, 1, 1, 4, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 0, 0, 3, 1, 1, 4, 1, 1, 0, 0, 0, 0, 0, 2, 2, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 4, 1, 0, 0, 2, 2, 1, 1, 2, 1, 0, 2, 0, 0, 1, 2, 1, 1, 0, 2, 1, 0, 1, 0, 2, 0, 0, 3, 2, 0, 0, 3, 1, 1, 0, 0, 1, 2, 1, 2, 2, 0, 3, 1, 1, 0, 1, 2, 0, 0, 2, 1, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 1, 0, 4, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 4, 0, 0, 2, 2, 0, 5, 0, 0, 0, 1, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 4, 0, 1, 1, 1, 0, 0, 0, 3, 0, 0, 2, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 0, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 1, 3, 0, 0, 1, 0, 0, 2, 0, 0, 1, 0, 1, 1, 3, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 6, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0, 1, 0, 4, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 3, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 3, 1, 0, 3, 0, 3, 1, 0, 2, 0, 2, 1, 2, 2, 5, 0, 0, 0, 1, 0, 1, 3, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 3, 0, 1, 0, 0, 1, 0, 1, 1, 1, 2, 2, 3, 1, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 6, 1, 0, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 4, 1, 1, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 3, 0, 0, 0, 0, 1, 1, 1, 0, 1, 2, 3, 2, 0, 0, 2, 0, 2, 0, 0, 1, 1, 0, 1, 3, 3, 1, 1, 1, 4, 0, 0, 1, 1, 0, 0, 0, 3, 2, 0, 1, 0, 0, 0, 2, 0, 0, 1, 3, 0, 2, 3, 1, 0, 0, 0, 0, 1, 2, 2, 3, 2, 2, 3, 1, 1, 2, 1, 0, 0, 0, 1, 0, 1, 2, 0, 2, 0, 5, 0, 0, 1, 0, 2, 1, 3, 0, 1, 1, 0, 0, 6, 3, 4, 6, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 3, 1, 2, 0, 1, 2, 2, 3, 3, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 3, 0, 2, 2, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 0, 0, 0, 3, 2, 2, 1, 1, 1, 0, 2, 5, 2, 1, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 3, 3, 0, 4, 0, 1, 0, 1, 0, 1, 1, 0, 1, 4, 1, 0, 0, 1, 1, 1, 1, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 2, 2, 1, 6, 0, 1, 0, 2, 1, 1, 2, 1, 3, 3, 0, 0, 2, 0, 2, 0, 0, 3, 3, 0, 2, 0, 1, 0, 3, 1, 1, 1, 0, 1, 2, 0, 1, 0, 2, 0, 1, 0, 2, 0, 0, 0, 0, 3, 1, 3, 1, 0, 1, 2, 1, 2, 2, 0, 4, 1, 2, 2, 2, 3, 0, 0, 0, 0, 0, 4, 2, 4, 3, 0, 0, 2, 6, 1, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 0, 5, 1, 8, 2, 0, 0, 2, 1, 2, 0, 1, 1, 1, 2, 1, 1, 8, 2, 0, 1, 3, 1, 2, 0, 2, 2, 5, 1, 1, 4, 5, 2, 2, 3, 1, 2, 0, 1, 0, 4, 2, 2, 4, 1, 3, 3, 6, 1, 3, 0, 1, 1, 0, 2, 3, 5, 3, 2, 3, 2, 2, 1, 1, 0, 1, 2, 4, 1, 1, 1, 3, 2, 1, 0, 1, 0, 1, 2, 4, 1, 0, 3, 4, 3, 0, 1, 0, 2, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 1, 0, 1, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 1, 1, 1, 1, 4, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 4, 0, 1, 4, 0, 1, 1, 2, 0, 2, 2, 0, 3, 2, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 2, 1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 2, 2, 3, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 2, 1, 0, 4, 1, 3, 1, 2, 0, 1, 2, 1, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 1, 1, 2, 0, 2, 1, 2, 1, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 1, 0, 1, 1, 3, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0, 3, 0, 0, 1, 0, 0, 2, 2, 2, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 1, 2, 0, 0, 0, 1, 0, 1, 0, 2, 0, 3, 0, 0, 0, 6, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 3, 3, 5, 4, 0, 3, 0, 0, 3, 0, 2, 0, 4, 1, 1, 2, 0, 0, 2, 1, 2, 2, 2, 0, 2, 0, 0, 2, 2, 1, 2, 0, 0, 1, 2, 3, 1, 4, 2, 0, 2, 1, 0, 2, 0, 3, 3, 4, 2, 1, 0, 3, 0, 4, 4, 1, 0, 0, 2, 2, 1, 1, 5, 0, 1, 0, 1, 1, 0, 5, 1, 0, 2, 0, 5, 8, 3, 2, 1, 0, 4, 0, 0, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 1, 5, 3, 1, 0, 2, 1, 1, 2, 3, 3, 2, 1, 2, 0, 1, 1, 3, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 2, 1, 1, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 1, 1, 0, 0, 1, 2, 4, 5, 2, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 2, 2, 0, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 5, 4, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 4, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 3, 18, 12, 4, 3, 0, 0, 0, 0, 1, 0, 0, 1, 5, 0, 2, 0, 1, 1, 0, 1, 1, 0, 0, 2, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 2, 1, 7, 3, 3, 0, 1, 1, 2, 2, 3, 3, 2, 0, 0, 0, 5, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 3, 1, 3, 0, 0, 3, 0, 0, 1, 0, 0, 1, 3, 2, 1, 1, 2, 0, 1, 2, 1, 2, 1, 0, 0, 0, 3, 0, 1, 1, 1, 1, 2, 3, 0, 1, 0, 0, 1, 3, 1, 1, 1, 3, 0, 3, 4, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 2, 5, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 3, 2, 2, 3, 11, 3, 3, 2, 2, 0, 0, 0, 1, 3, 9, 5, 10, 3, 2, 1, 4, 0, 0, 0, 0, 2, 0, 0, 0, 1, 4, 4, 1, 1, 0, 1, 2, 0, 1, 1, 0, 0, 0, 1, 1, 1, 2, 1, 4, 2, 2, 2, 1, 1, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 4, 1, 1, 0, 0, 5, 1, 1, 3, 1, 1, 0, 2, 1, 2, 0, 2, 2, 1, 0, 1, 1, 1, 2, 2, 1, 2, 3, 1, 1, 2, 1, 2, 0, 3, 1, 2, 0, 0, 0, 1, 3, 2, 0, 0, 1, 1, 1, 0, 1, 2, 0, 2, 0, 1, 0, 1, 1, 1, 1, 0, 2, 0, 1, 0, 2, 1, 3, 2, 7, 0, 0, 0, 0, 1, 1, 1, 2, 0, 2, 1, 6, 0, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 2, 4, 4, 3, 3, 4, 0, 0, 0, 3, 0, 0, 2, 2, 0, 1, 0, 4, 1, 1, 2, 0, 1, 2, 0, 0, 2, 1, 2, 2, 2, 3, 0, 1, 2, 1, 3, 1, 0, 1, 2, 1, 1, 0, 1, 3, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 1, 1, 4, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 2, 3, 0, 0, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 2, 4, 0, 1, 2, 4, 2, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 4, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 2, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 2, 2, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 2, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 2, 1, 1, 0, 2, 2, 1, 4, 0, 0, 0, 0, 2, 1, 1, 0, 0, 2, 3, 0, 0, 1, 0, 0, 1, 2, 0, 1, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 1, 3, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 4, 1, 0, 0, 3, 0, 1, 2, 1, 1, 3, 2, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 3, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 4, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 1, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 2, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 2, 0, 1, 1, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2, 3, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 2, 2, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 6, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 1]\n",
      "Loading model to predict...\n",
      "The rmse of loaded model's prediction is: 86209.39417363291\n"
     ]
    }
   ],
   "source": [
    "num_train, num_feature = X_train.shape\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train, free_raw_data=False)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train, free_raw_data=False)\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'mse',\n",
    "    'num_leaves': 40,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "# generate feature names\n",
    "feature_name = ['feature_' + str(col) for col in range(num_feature)]\n",
    "\n",
    "print('Starting training...')\n",
    "# feature_name and categorical_feature\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_train,  # eval training data\n",
    "                feature_name=feature_name,\n",
    "                categorical_feature=[21])\n",
    "\n",
    "print('Finished first 10 rounds...')\n",
    "print('Saving model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Dumping model to JSON...')\n",
    "# dump model to JSON (and save to file)\n",
    "model_json = gbm.dump_model()\n",
    "\n",
    "with open('model.json', 'w+') as f:\n",
    "    json.dump(model_json, f, indent=4)\n",
    "\n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importance()))\n",
    "\n",
    "print('Loading model to predict...')\n",
    "# load model to predict\n",
    "bst = lgb.Booster(model_file='model.txt')\n",
    "# can only predict with the best iteration (or the saving iteration)\n",
    "y_pred = bst.predict(X_test)\n",
    "# eval with loaded model \n",
    "print(\"The rmse of loaded model's prediction is:\", mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CHUO81Ead0n7",
    "outputId": "607c7adb-531b-4b2f-df74-c3f2638ac1b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of pickled model's prediction is: 86209.45741192876\n"
     ]
    }
   ],
   "source": [
    "# dump model with pickle\n",
    "with open('model.pkl', 'wb') as fout:\n",
    "    pickle.dump(gbm, fout)\n",
    "# load model with pickle to predict\n",
    "with open('model.pkl', 'rb') as fin:\n",
    "    pkl_bst = pickle.load(fin)\n",
    "# can predict with any iteration when loaded in pickle way\n",
    "y_pred = pkl_bst.predict(X_test, num_iteration=7)\n",
    "# eval with loaded model\n",
    "print(\"The rmse of pickled model's prediction is:\", mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4N85QHTieki4"
   },
   "outputs": [],
   "source": [
    "#################################################################\n",
    "#################################################################\n",
    "#################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "Sc_Ytyr5RiqC",
    "outputId": "26f3000e-634f-4336-f46a-a2b4451ca183"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "# SECOND ROUND\n",
    "params = {}\n",
    "params['learning_rate'] = 0.003\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'binary'\n",
    "params['metric'] = 'binary_logloss'\n",
    "params['sub_feature'] = 0.5\n",
    "params['num_leaves'] = 10\n",
    "params['min_data'] = 50\n",
    "params['max_depth'] = 10\n",
    "\n",
    "clf = lgb.train(params, lgb_train, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ii9xNkj1R5e4",
    "outputId": "19b7824a-ba8b-44d5-b6c9-905c7711f788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rmse of pickled model's prediction is: 86209.4440394231\n"
     ]
    }
   ],
   "source": [
    "#Prediction\n",
    "y_pred=clf.predict(X_test)\n",
    "#convert into binary values\n",
    "for i in range(0,99):\n",
    "    if y_pred[i]>=.5:       # setting threshold to .5\n",
    "        y_pred[i]=1\n",
    "    else:  \n",
    "        y_pred[i]=0\n",
    "print(\"The rmse of pickled model's prediction is:\", mean_squared_error(y_test, y_pred) ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "colab_type": "code",
    "id": "HhAVTyWISDQk",
    "outputId": "19496d16-ba00-48fc-83d9-e264c1c3bd7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 210.41it/s, best loss: -0.24999965642266697]\n",
      "{'x': 0.5005861547005761}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbd470762e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define objective function\n",
    "def f(x):\n",
    "    return {'loss': x ** 2 - x, 'status': STATUS_OK}\n",
    "\n",
    "# Run hyperopt optimization\n",
    "trials = Trials()\n",
    "result = fmin(\n",
    "    fn=f,                           # objective function\n",
    "    space=hp.uniform('x', -1, 1),   # parameter space\n",
    "    algo=tpe.suggest,               # surrogate algorithm\n",
    "    max_evals=500,                  # no. of evaluations\n",
    "    trials=trials                   # trials object that keeps track of the sample results (optional)\n",
    ")\n",
    "\n",
    "# Print the optimized parameters\n",
    "print(result)   # {'x': 0.5000833960783931}\n",
    "\n",
    "# Extract and plot the trials \n",
    "x = trials.vals['x']\n",
    "y = [x['loss'] for x in trials.results]\n",
    "plt.pyplot.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8oM9hrUFSb9C"
   },
   "outputs": [],
   "source": [
    "\n",
    "# XGB parameters\n",
    "xgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "}\n",
    "xgb_fit_params = {\n",
    "    'eval_metric': 'rmse',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "xgb_para = dict()\n",
    "xgb_para['reg_params'] = xgb_reg_params\n",
    "xgb_para['fit_params'] = xgb_fit_params\n",
    "xgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))\n",
    "\n",
    "\n",
    "# LightGBM parameters\n",
    "lgb_reg_params = {\n",
    "    'learning_rate':    hp.choice('learning_rate',    np.arange(0.05, 0.31, 0.05)),\n",
    "    'max_depth':        hp.choice('max_depth',        np.arange(5, 16, 1, dtype=int)),\n",
    "    'min_child_weight': hp.choice('min_child_weight', np.arange(1, 8, 1, dtype=int)),\n",
    "    'colsample_bytree': hp.choice('colsample_bytree', np.arange(0.3, 0.8, 0.1)),\n",
    "    'subsample':        hp.uniform('subsample', 0.8, 1),\n",
    "    'n_estimators':     100,\n",
    "}\n",
    "lgb_fit_params = {\n",
    "    'eval_metric': 'l2',\n",
    "    'early_stopping_rounds': 10,\n",
    "    'verbose': False\n",
    "}\n",
    "lgb_para = dict()\n",
    "lgb_para['reg_params'] = lgb_reg_params\n",
    "lgb_para['fit_params'] = lgb_fit_params\n",
    "lgb_para['loss_func' ] = lambda y, pred: np.sqrt(mean_squared_error(y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bB3gx3cITf8x",
    "outputId": "7ecadfd6-cfdf-487f-a554-9753696a8f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 5.7220458984375e-06\n",
      "[11:17:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:18:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:19:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:19:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:20:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:21:17] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:22:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:22:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:23:51] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:26:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:28:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:30:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:31:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:35:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:38:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:42:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:44:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:46:14] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:46:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:47:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:48:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:52:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:55:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[11:58:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:01:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:04:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:07:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:10:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:16:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:19:48] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:20:56] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:22:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:23:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:25:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:26:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:27:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:30:16] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:32:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:33:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:33:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:37:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:42:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:43:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:44:19] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:45:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:45:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:46:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:47:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:48:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:50:41] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:51:10] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:52:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:53:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:56:50] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:57:32] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:58:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:02:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:07:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:08:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:09:34] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:11:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:12:52] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:13:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:16:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:17:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:18:33] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:19:18] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:20:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:22:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:24:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:24:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:30:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:31:21] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:35:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:36:40] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:39:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:42:54] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:46:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:48:46] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:51:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:55:01] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[13:58:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:00:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:01:30] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:01:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:03:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:06:55] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:07:20] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:10:28] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:10:59] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:14:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:15:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:16:00] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:18:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:22:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:24:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:25:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[14:28:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "100%|██████████| 100/100 [3:14:48<00:00, 162.29s/it, best loss: 51914.2042677069]\n"
     ]
    }
   ],
   "source": [
    "# We now apply the hiperoptimization class for both XGB and LightGBM models\n",
    "\n",
    "obj = HPOpt(X_train, X_test, y_train, y_test)\n",
    "xgb_opt = obj.process(fn_name='xgb_reg', space=xgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JRNDqQCyhi11",
    "outputId": "b7f72745-a40b-4970-9c42-d805872991ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [1:52:11<00:00, 68.13s/it, best loss: 51753.51522429675]\n"
     ]
    }
   ],
   "source": [
    "lgb_opt = obj.process(fn_name='lgb_reg', space=lgb_para, trials=Trials(), algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iz-yiDbOkFmK"
   },
   "outputs": [],
   "source": [
    "# XGB RMSE -> 51914.20\n",
    "# LightGBM -> 51753.51\n",
    "\n",
    "# With a very small difference, we select our LightGBM model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "eolo_lightgbm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
